{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import layers, models, Sequential, Input, Model\n",
    "from tensorflow.data.experimental import cardinality\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.python.ops import image_ops\n",
    "from tensorflow.python.ops import io_ops\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_CNN_models = r'C:\\Users\\pitip\\code\\ClaireLeroux44\\ArtRecognition\\models\\Full_training'\n",
    "model_name = '20201214_150118_VGG16_v4_31'\n",
    "\n",
    "path_KNN_models = r'C:\\Users\\pitip\\code\\ClaireLeroux44\\ArtRecognition\\models\\KNN_models\\CNN_comparison'\n",
    "KNN_model = 'KNN_model_20201214_150118_VGG16_v4_31_Top_12.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = r'C:\\Users\\pitip\\OneDrive\\Bureau\\raw_data\\Donnees_tests\\Data_test'\n",
    "#test_dataset_path = r'C:\\Users\\pitip\\OneDrive\\Bureau\\raw_data\\Clean_Data\\Recog_test_dataset\\_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_info = pd.read_csv('../ArtRecognition/data/all_data_info.csv')\n",
    "artist_number = pd.read_csv('../ArtRecognition/data/artists_numbers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_image(path, image_size, num_channels, interpolation):\n",
    "    img = io_ops.read_file(path)\n",
    "    img = image_ops.decode_image(img, channels=num_channels, expand_animations=False)\n",
    "    img = image_ops.resize_images_v2(img, image_size, method=interpolation)\n",
    "    img.set_shape((image_size[0], image_size[1], num_channels))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Embedding_generation(root_path, embedding_model):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for root, dirs, files in os.walk(root_path, topdown=False):\n",
    "        for name in files:\n",
    "            img_list.append(os.path.join(root, name))\n",
    "            label_list.append(name)\n",
    "\n",
    "    #img_list = img_list[:5]\n",
    "    #label_list = label_list[:5]\n",
    "    DF_list = []\n",
    "    for im_path, label in zip(img_list, label_list):\n",
    "        im_iops = path_to_image(im_path, IMG_SIZE, 3, 'bilinear')\n",
    "        im_iops = np.expand_dims(im_iops,axis =0)\n",
    "\n",
    "        image_embedding = embedding_model.predict(im_iops)\n",
    "        DF_list.append(pd.DataFrame(image_embedding, index=[label]))\n",
    "    Embeddings_df = pd.concat(DF_list)\n",
    "    return Embeddings_df, img_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_prediction(knr_model, test_path, embedding_model):\n",
    "    image_embeddings_test, img_list_test, label_list_test = Embedding_generation(test_path, embedding_model)\n",
    "    print(f\"Test_dataset embedding computed, shape: {image_embeddings_test.shape}\")\n",
    "\n",
    "    dist, pred_label = knr_model.kneighbors(X=image_embeddings_test, n_neighbors=3, return_distance=True)\n",
    "    pred_1 = []\n",
    "    dist_1 = []\n",
    "    pred_2 = []\n",
    "    dist_2 = []\n",
    "    pred_3 = []\n",
    "    dist_3 = []\n",
    "    for i in range(len(img_list_test)):\n",
    "        pred_1.append(label_list.iloc[pred_label[i][0]][0])\n",
    "        pred_2.append(label_list.iloc[pred_label[i][1]][0])\n",
    "        pred_3.append(label_list.iloc[pred_label[i][2]][0])\n",
    "        dist_1.append(dist[i][0])\n",
    "        dist_2.append(dist[i][1])\n",
    "        dist_3.append(dist[i][2])\n",
    "\n",
    "    print('Neighbors identified')\n",
    "    if test_path == r'C:\\Users\\pitip\\OneDrive\\Bureau\\raw_data\\Clean_Data\\Recog_test_dataset\\_all':\n",
    "        results_df = pd.DataFrame({'Label': label_list_test, 'Original_image': [os.path.splitext(s)[0].split('_')[0]+'.jpg' for s in label_list_test],\n",
    "                           'Transform':[int(os.path.splitext(s)[0].split('_')[-1]) if len(os.path.splitext(s)[0].split('_'))==2 else 0 for s in label_list_test], \n",
    "                           'pred_1':pred_1,'pred_2':pred_2, 'pred_3':pred_3, 'dist_1':dist_1, 'dist_2':dist_2, 'dist_3':dist_3})\n",
    "    else:\n",
    "        results_df = pd.DataFrame({'Label': label_list_test, 'pred_1':pred_1,'pred_2':pred_2, 'pred_3':pred_3, 'dist_1':dist_1, 'dist_2':dist_2, 'dist_3':dist_3})\n",
    "    \n",
    "    return results_df, img_list_test, label_list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3_accuracy(results_df):\n",
    "    results_df2 = results_df[['Label', 'Original_image', 'Transform', 'pred_1', 'pred_2', 'pred_3']].copy()\n",
    "    results_df2['1_st'] = (results_df2['pred_1']==results_df2['Original_image'])*1\n",
    "    results_df2['2_nd'] = (results_df2['pred_2']==results_df2['Original_image'])*1\n",
    "    results_df2['3_rd'] = (results_df2['pred_3']==results_df2['Original_image'])*1\n",
    "    \n",
    "    results_df2['in_top_3'] = results_df2[['1_st', '2_nd', '3_rd']].max(axis = 1)\n",
    "    \n",
    "    print(f\"Top 3 accuracy: {results_df2['in_top_3'].sum()/len(results_df2['in_top_3']):.4f}\")\n",
    "    return results_df2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data prediction and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 20201214_150118_VGG16_v4_31 loaded\n"
     ]
    }
   ],
   "source": [
    "model = load_model('/Users/marie.dausse/code/mariedos/clairel/ArtRecognition/models/model_v6')\n",
    "print(f\"Model {model_name} loaded\")\n",
    "\n",
    "layer_outputs = [model.layers[-1].input]\n",
    "embedding_model = models.Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid file path or buffer object type: <class 'sklearn.neighbors._regression.KNeighborsRegressor'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d5c4c85c6cc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/marie.dausse/code/mariedos/clairel/ArtRecognition/models/KNN_models/model3.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"label_list_{model_name}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     )\n\u001b[1;32m    437\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Invalid file path or buffer object type: {type(filepath_or_buffer)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid file path or buffer object type: <class 'sklearn.neighbors._regression.KNeighborsRegressor'>"
     ]
    }
   ],
   "source": [
    "knr = joblib.load('/Users/marie.dausse/code/mariedos/clairel/ArtRecognition/models/KNN_models/model3.joblib')\n",
    "label_list = pd.read_csv(knr, f\"label_list_{model_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a2771032024a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNN_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-453ae475bf70>\u001b[0m in \u001b[0;36mKNN_prediction\u001b[0;34m(knr_model, test_path, embedding_model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKNN_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknr_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage_embeddings_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test_dataset embedding computed, shape: {image_embeddings_test.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_embeddings_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-326d43cfc2de>\u001b[0m in \u001b[0;36mEmbedding_generation\u001b[0;34m(root_path, embedding_model)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimage_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_iops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mDF_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mEmbeddings_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDF_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEmbeddings_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "results_df, img_list_test, label_list_test = KNN_prediction(knr, test_dataset_path, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-17bb966b436f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_dataset_path == r'C:\\Users\\pitip\\OneDrive\\Bureau\\raw_data\\Clean_Data\\Recog_test_dataset\\_all':\n",
    "    accuracy_score(results_df['Original_image'], results_df['pred_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_dataset_path == r'C:\\Users\\pitip\\OneDrive\\Bureau\\raw_data\\Clean_Data\\Recog_test_dataset\\_all':\n",
    "    transform_list = ['original', 'crop', 'extend', 'rotate', 'contrast', 'color balance', 'noise', 'all modif']\n",
    "    acc_list = []\n",
    "    acc = accuracy_score(results_df['Original_image'], results_df['pred_1'])\n",
    "    print(f\"Overall top 1 accuracy: {acc:.4f}\")\n",
    "    results_df_top_3 = top3_accuracy(results_df)\n",
    "    for i, transform in enumerate(transform_list):\n",
    "        transform_results_df = results_df.loc[results_df['Transform']==i]\n",
    "        acc = accuracy_score(transform_results_df['Original_image'], transform_results_df['pred_1'])\n",
    "        acc_list.append(acc)\n",
    "        top_3_transform_results_df = results_df_top_3.loc[results_df_top_3['Transform']==i]\n",
    "        top3_acc = top_3_transform_results_df['in_top_3'].sum()/len(top_3_transform_results_df['in_top_3'])\n",
    "        print(f\"Transformation method: {transform} - Accuracy: {acc:.4f} - Top 3 accuracy: {top3_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_data_dir = r'C:\\Users\\pitip\\OneDrive\\Bureau\\raw_data\\Clean_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3): #len(results_df)):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20,4))\n",
    "    \n",
    "    path_img_orig = os.path.join(test_dataset_path, img_list_test[j])\n",
    "    img = plt.imread(path_img_orig)\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Test image: ')\n",
    "    \n",
    "    for i in range(3):\n",
    "        id_im = results_df[f\"pred_{i+1}\"].iloc[j]\n",
    "        art_name = all_data_info.loc[all_data_info['new_filename']==id_im, 'artist'].values[0]\n",
    "        art_id = artist_number.loc[artist_number['artist']==art_name, 'artist_number'].values[0]\n",
    "        art_id_train = all_data_info.loc[all_data_info['new_filename']==id_im, 'in_train'].values[0]\n",
    "        if art_id_train=='True':\n",
    "            train_test_dir = 'Train'\n",
    "        else:\n",
    "            train_test_dir = 'Test'\n",
    "        path_img = os.path.join(DB_data_dir, train_test_dir, art_id, id_im)\n",
    "        img = plt.imread(path_img)\n",
    "        ax[i+1].imshow(img)\n",
    "        ax[i+1].axis('off')\n",
    "        ax[i+1].set_title(f'Prediction: {i+1}: distance: {results_df[f\"dist_{i+1}\"].iloc[j]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
